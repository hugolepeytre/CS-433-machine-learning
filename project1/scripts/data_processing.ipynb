{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T15:53:40.999407Z",
     "start_time": "2020-10-22T15:53:29.802922Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.7/site-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T15:53:50.023512Z",
     "start_time": "2020-10-22T15:53:41.002783Z"
    }
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = '../data/train.csv'\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T15:53:50.058553Z",
     "start_time": "2020-10-22T15:53:50.025567Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000,) (250000, 30) (250000,)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape, tX.shape,ids.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T15:57:21.983550Z",
     "start_time": "2020-10-22T15:57:21.943880Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_nan(tX):\n",
    "    \"\"\"\n",
    "    Label the -999 values as NaN\n",
    "    \"\"\"\n",
    "    tX_copy = np.copy(tX)\n",
    "    tX_copy[tX_copy == -999] = np.nan\n",
    "    return tX_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T15:57:22.385212Z",
     "start_time": "2020-10-22T15:57:22.343172Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_empty_columns(tX, threshold = 0.4):\n",
    "    \"\"\"\n",
    "    Remove feature columns containing more than the specified threshold proportion of NaN\n",
    "    \"\"\"\n",
    "    tX_copy = np.copy(tX)\n",
    "    #For each column compute the ratio of nan values over the number of rows\n",
    "    prop_empty_column = (np.isnan(tX_copy)).sum(axis=0) / len(tX_copy)\n",
    "    \n",
    "    column_mask = prop_empty_column < threshold\n",
    "    return tX_copy[:, column_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T15:57:22.589542Z",
     "start_time": "2020-10-22T15:57:22.542857Z"
    }
   },
   "outputs": [],
   "source": [
    "def copy_data(y, tX, ids):\n",
    "    return np.copy(y), np.copy(tX) , np.copy(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T15:57:22.784460Z",
     "start_time": "2020-10-22T15:57:22.741447Z"
    }
   },
   "outputs": [],
   "source": [
    "def filter_nan(y, tX, ids, remove=True, replace_val=0):\n",
    "    \"\"\"\n",
    "    Filter the nan (-999) values, by either removing the rows or replacing by the specified replace_val.\n",
    "    \"\"\"   \n",
    "    y_copy, tX_copy, ids_copy = copy_data(y, tX, ids)\n",
    "    mask = np.isnan(tX_copy)# True if Nan, False otherwise\n",
    "    \n",
    "    if remove:\n",
    "        # Remove the rows containing any NaN\n",
    "        row_mask = ~mask.any(axis=1) # sets to False any rows containing NaN\n",
    "        tX_copy, y_copy, ids_copy = tX_copy[row_mask], y_copy[row_mask], ids_copy[row_mask]\n",
    "    else:\n",
    "        #Replace NaN values by replace_val\n",
    "        tX_copy[mask] = replace_val\n",
    "        \n",
    "    return y_copy, tX_copy, ids_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T16:01:09.957039Z",
     "start_time": "2020-10-22T16:01:09.908592Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_outliers(y, tX, ids):\n",
    "    \"\"\"\n",
    "    Remove outliers feature points using Interquartile range.\n",
    "    \"\"\"\n",
    "    print(\"\"\"TODO: only remove outliers when max - min > threshold like 10\n",
    "    Doubt with DER_deltar_tau_lep and PRI_jet_all_pt\"\"\")\n",
    "    y_copy, tX_copy, ids_copy = copy_data(y, tX, ids)\n",
    "    # Compute first and third quartiles and the Interquartile range\n",
    "    Q1 = np.percentile(tX_copy, 25, axis=0) \n",
    "    Q3 = np.percentile(tX_copy, 75, axis=0)\n",
    "    IQR = Q3 - Q1\n",
    "    mask = (tX_copy >= Q1 - 1.5 * IQR) & (tX_copy <= Q3 + 1.5 * IQR) # set to False any entry outside the interquartile range\n",
    "\n",
    "    print(pd.DataFrame(data=mask).head(10))\n",
    "    threshold_range = 10\n",
    "    col_mask = (tX.max(axis=0) - tX.min(axis=0)) < threshold_range #set to False any feature with range bigger than threshold\n",
    "    mask = mask | col_mask\n",
    "    print(pd.DataFrame(data=col_mask).head(10))\n",
    "    print(pd.DataFrame(data=mask).head(10))\n",
    "    row_mask = mask.all(axis=1) #sets to False rows containing any outliers    \n",
    "    \n",
    "    return y_copy[row_mask], tX_copy[row_mask], ids_copy[row_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T15:57:23.168039Z",
     "start_time": "2020-10-22T15:57:23.127486Z"
    }
   },
   "outputs": [],
   "source": [
    "def noncategorical_columns(tX):\n",
    "    \"\"\"\n",
    "    Computes the columns with more that 10 unique values\n",
    "    \"\"\"\n",
    "     # count the number of unique values\n",
    "    nunique_col = (np.diff(np.sort(tX, axis=0), axis=0) != 0).sum(axis=0) + 1 \n",
    "    noncategorical_col = nunique_col > 10 #set to True columns with more than 10 unique elements\n",
    "    return noncategorical_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T15:57:23.384104Z",
     "start_time": "2020-10-22T15:57:23.346798Z"
    }
   },
   "outputs": [],
   "source": [
    "def scale(tX, method=\"standard\"):\n",
    "    \"\"\"\n",
    "    Scale noncategorical features using the specified method. Possible methods: standard, min-max\n",
    "    \"\"\"\n",
    "    tX_copy = np.copy(tX)\n",
    "    noncategorical_col = noncategorical_columns(tX_copy)\n",
    "    tX_noncat = tX_copy[:,noncategorical_col]\n",
    "    \n",
    "    if method == \"standard\": \n",
    "        #Standardize the data\n",
    "        tX_copy[:,noncategorical_col] = (tX_noncat - tX_noncat.mean(axis=0)) / tX_noncat.std(axis=0) \n",
    "    else:\n",
    "        #Apply a min-max normalization to scale data between 0 and 1\n",
    "        col_min = tX_noncat.min(axis=0)\n",
    "        col_max = tX_noncat.max(axis=0)\n",
    "        tX_copy[:,noncategorical_col] = (tX_noncat - col_min) / (col_max - col_min)\n",
    "    return tX_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T15:57:23.677038Z",
     "start_time": "2020-10-22T15:57:23.631215Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_correlated_features(tX, threshold=0.9):\n",
    "    \"\"\"\n",
    "    Compute the correlations between each feature and remove features that have a correlation greater\n",
    "    than the specified threshold\n",
    "    \"\"\"\n",
    "    tX_copy = np.copy(tX)\n",
    "    noncategorical_col = noncategorical_columns(tX_copy)\n",
    "    cat_idx = np.where(~noncategorical_col)[0] # index of non categorical features\n",
    "    tX_noncat = tX_copy[:,noncategorical_col]\n",
    "    \n",
    "    corr_matrix = np.corrcoef(tX_noncat, rowvar=False)\n",
    "    \n",
    "    #set to False highly correlated columns\n",
    "    nb_col = len(corr_matrix)\n",
    "    columns = np.full((nb_col,), True, dtype=bool)\n",
    "    for i in range(nb_col):\n",
    "        for j in range(i+1, nb_col):\n",
    "            if corr_matrix[i,j] >= threshold:\n",
    "                if columns[i]:\n",
    "                    columns[j] = False\n",
    "     \n",
    "    #remove correlated features and concat categorical features\n",
    "    return np.c_[tX_noncat[:,columns],tX_copy[:,cat_idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T15:57:24.805776Z",
     "start_time": "2020-10-22T15:57:24.765903Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_pri_colums(tX):\n",
    "    pass\n",
    "\n",
    "def remove_der_columns(tX):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T15:57:25.070119Z",
     "start_time": "2020-10-22T15:57:25.026300Z"
    }
   },
   "outputs": [],
   "source": [
    "def pipeline(y, tX, ids):\n",
    "    tX_nan = set_nan(tX)\n",
    "    tX_columns = remove_empty_columns(tX_nan)\n",
    "    y_filtered, tX_filtered, ids_filtered = filter_nan(y, tX_columns, ids)\n",
    "    y_outliers, tX_outliers, ids_outliers = remove_outliers(y_filtered, tX_filtered, ids_filtered)\n",
    "    tX_scale = scale(tX_outliers, method=\"standard\")\n",
    "    tX_corr = remove_correlated_features(tX_scale, threshold=0.9)\n",
    "    return tX_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-22T16:01:13.696885Z",
     "start_time": "2020-10-22T16:01:12.600524Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TODO: only remove outliers when max - min > threshold like 10\n",
      "    Doubt with DER_deltar_tau_lep and PRI_jet_all_pt\n",
      "     0     1     2     3     4     5     6      7     8      9   ...    13  \\\n",
      "0  True  True  True  True  True  True  True   True  True   True  ...  True   \n",
      "1  True  True  True  True  True  True  True   True  True   True  ...  True   \n",
      "2  True  True  True  True  True  True  True   True  True   True  ...  True   \n",
      "3  True  True  True  True  True  True  True  False  True   True  ...  True   \n",
      "4  True  True  True  True  True  True  True   True  True   True  ...  True   \n",
      "5  True  True  True  True  True  True  True   True  True   True  ...  True   \n",
      "6  True  True  True  True  True  True  True   True  True   True  ...  True   \n",
      "7  True  True  True  True  True  True  True   True  True   True  ...  True   \n",
      "8  True  True  True  True  True  True  True   True  True   True  ...  True   \n",
      "9  True  True  True  True  True  True  True   True  True  False  ...  True   \n",
      "\n",
      "     14     15    16    17    18    19    20    21    22  \n",
      "0  True   True  True  True  True  True  True  True  True  \n",
      "1  True   True  True  True  True  True  True  True  True  \n",
      "2  True   True  True  True  True  True  True  True  True  \n",
      "3  True   True  True  True  True  True  True  True  True  \n",
      "4  True   True  True  True  True  True  True  True  True  \n",
      "5  True  False  True  True  True  True  True  True  True  \n",
      "6  True   True  True  True  True  True  True  True  True  \n",
      "7  True   True  True  True  True  True  True  True  True  \n",
      "8  True   True  True  True  True  True  True  True  True  \n",
      "9  True   True  True  True  True  True  True  True  True  \n",
      "\n",
      "[10 rows x 23 columns]\n",
      "       0\n",
      "0  False\n",
      "1  False\n",
      "2  False\n",
      "3  False\n",
      "4   True\n",
      "5  False\n",
      "6  False\n",
      "7  False\n",
      "8   True\n",
      "9  False\n",
      "     0     1     2     3     4     5     6      7     8      9   ...    13  \\\n",
      "0  True  True  True  True  True  True  True   True  True   True  ...  True   \n",
      "1  True  True  True  True  True  True  True   True  True   True  ...  True   \n",
      "2  True  True  True  True  True  True  True   True  True   True  ...  True   \n",
      "3  True  True  True  True  True  True  True  False  True   True  ...  True   \n",
      "4  True  True  True  True  True  True  True   True  True   True  ...  True   \n",
      "5  True  True  True  True  True  True  True   True  True   True  ...  True   \n",
      "6  True  True  True  True  True  True  True   True  True   True  ...  True   \n",
      "7  True  True  True  True  True  True  True   True  True   True  ...  True   \n",
      "8  True  True  True  True  True  True  True   True  True   True  ...  True   \n",
      "9  True  True  True  True  True  True  True   True  True  False  ...  True   \n",
      "\n",
      "     14     15    16    17    18    19    20    21    22  \n",
      "0  True   True  True  True  True  True  True  True  True  \n",
      "1  True   True  True  True  True  True  True  True  True  \n",
      "2  True   True  True  True  True  True  True  True  True  \n",
      "3  True   True  True  True  True  True  True  True  True  \n",
      "4  True   True  True  True  True  True  True  True  True  \n",
      "5  True  False  True  True  True  True  True  True  True  \n",
      "6  True   True  True  True  True  True  True  True  True  \n",
      "7  True   True  True  True  True  True  True  True  True  \n",
      "8  True   True  True  True  True  True  True  True  True  \n",
      "9  True   True  True  True  True  True  True  True  True  \n",
      "\n",
      "[10 rows x 23 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.00116781,  0.60294873,  1.27197329, ...,  1.16307234,\n",
       "         0.25544962,  2.        ],\n",
       "       [ 1.79100178,  1.23888656,  1.54716042, ...,  0.39352041,\n",
       "         0.64881421,  1.        ],\n",
       "       [-0.711809  , -0.81307483, -0.69616427, ..., -1.3005739 ,\n",
       "        -0.34892147,  3.        ],\n",
       "       ...,\n",
       "       [-0.72007049,  1.88954019,  0.35822785, ..., -1.53764989,\n",
       "         1.62671638,  1.        ],\n",
       "       [ 0.82493433,  1.56486369,  0.82224994, ..., -0.66441097,\n",
       "         1.39973289,  1.        ],\n",
       "       [-0.15941388,  0.93260481,  0.15310963, ...,  0.97405958,\n",
       "        -0.08061817,  1.        ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline(y, tX, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
