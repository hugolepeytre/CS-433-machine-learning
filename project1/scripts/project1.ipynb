{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-15T15:11:29.517388Z",
     "start_time": "2020-10-15T15:11:29.116920Z"
    }
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-15T15:11:29.550025Z",
     "start_time": "2020-10-15T15:11:29.520226Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_FOLDER = '../data/'\n",
    "DATA_ZIP = DATA_FOLDER + 'datasets.zip'\n",
    "\n",
    "DATA_TRAIN_PATH = DATA_FOLDER + 'train.csv'\n",
    "DATA_TRAIN_PATH_CLEAN = DATA_FOLDER + 'train_clean.csv'\n",
    "DATA_TEST_PATH = DATA_FOLDER + 'test.csv' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-15T15:11:39.980496Z",
     "start_time": "2020-10-15T15:11:29.620276Z"
    }
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "from split_data import *\n",
    "\n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)\n",
    "y_clean, tX_clean, ids_clean = load_csv_data(DATA_TRAIN_PATH_CLEAN)\n",
    "\n",
    "split_ratio = 0.8\n",
    "tX_train, tX_validation, y_train, y_validation = split_data(tX, y, split_ratio)\n",
    "tX_train_clean, tX_validation_clean, y_train_clean, y_validation_clean = split_data(tX_clean, y_clean, split_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-15T15:11:40.026036Z",
     "start_time": "2020-10-15T15:11:39.984297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw set : \n",
      "               Training       Validation     \n",
      "Features       (200000, 30)   (50000, 30)    \n",
      "Labels         (200000,)      (50000,)       \n",
      "\n",
      "Clean set : \n",
      "               Training       Validation     \n",
      "Features       (60122, 23)    (15031, 23)    \n",
      "Labels         (60122,)       (15031,)       \n"
     ]
    }
   ],
   "source": [
    "print(\"Raw set : \")\n",
    "row_format = \"{:<15}\" * 3\n",
    "print(row_format.format(\"\", \"Training\", \"Validation\"))\n",
    "print(row_format.format(\"Features\", str(tX_train.shape), str(tX_validation.shape)))\n",
    "print(row_format.format(\"Labels\", str(y_train.shape), str(y_validation.shape)))\n",
    "\n",
    "print(\"\\nClean set : \")\n",
    "row_format = \"{:<15}\" * 3\n",
    "print(row_format.format(\"\", \"Training\", \"Validation\"))\n",
    "print(row_format.format(\"Features\", str(tX_train_clean.shape), str(tX_validation_clean.shape)))\n",
    "print(row_format.format(\"Labels\", str(y_train_clean.shape), str(y_validation_clean.shape)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do your thing crazy machine learning thing here :) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-15T15:17:26.638426Z",
     "start_time": "2020-10-15T15:17:26.280876Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Descent(0/49): loss=0.5, w0=0.0038923184473918355, w1=-0.002478739706425339\n",
      "Gradient Descent(1/49): loss=0.4934845902115996, w0=0.007680747564935643, w1=-0.004905564156974364\n",
      "Gradient Descent(2/49): loss=0.48734514202299334, w0=0.011368188356217699, w1=-0.0072818876359016195\n",
      "Gradient Descent(3/49): loss=0.481557932855642, w0=0.014957457335966502, w1=-0.00960907846090936\n",
      "Gradient Descent(4/49): loss=0.4761008566424111, w0=0.01845128911508111, w1=-0.011888460662830693\n",
      "Gradient Descent(5/49): loss=0.47095330629775894, w0=0.021852338901950794, w1=-0.014121315599300181\n",
      "Gradient Descent(6/49): loss=0.46609606517732843, w0=0.025163184922946988, w1=-0.016308883505120567\n",
      "Gradient Descent(7/49): loss=0.46151120681354457, w0=0.02838633076486188, w1=-0.018452364981920304\n",
      "Gradient Descent(8/49): loss=0.4571820022718942, w0=0.03152420764196883, w1=-0.020552922429587568\n",
      "Gradient Descent(9/49): loss=0.45309283452581534, w0=0.0345791765902808, w1=-0.022611681421861877\n",
      "Gradient Descent(10/49): loss=0.44922911929698967, w0=0.03755353059149061, w1=-0.024629732028364378\n",
      "Gradient Descent(11/49): loss=0.44557723185265286, w0=0.04044949662898679, w1=-0.026608130085252583\n",
      "Gradient Descent(12/49): loss=0.44212443929265677, w0=0.04326923767825176, w1=-0.028547898416592995\n",
      "Gradient Descent(13/49): loss=0.43885883789675606, w0=0.04601485463386667, w1=-0.03045002800845809\n",
      "Gradient Descent(14/49): loss=0.435769295137214, w0=0.04868838817526655, w1=-0.032315479137669426\n",
      "Gradient Descent(15/49): loss=0.4328453959936019, w0=0.051291820573312864, w1=-0.03414518245702886\n",
      "Gradient Descent(16/49): loss=0.43007739323583744, w0=0.05382707743967636, w1=-0.03594004003880222\n",
      "Gradient Descent(17/49): loss=0.4274561613682764, w0=0.05629602942095167, w1=-0.03770092637814655\n",
      "Gradient Descent(18/49): loss=0.42497315395225765, w0=0.05870049383935697, w1=-0.039428689358101336\n",
      "Gradient Descent(19/49): loss=0.42262036404706527, w0=0.06104223628180548, w1=-0.0411241511776962\n",
      "Gradient Descent(20/49): loss=0.4203902875300008, w0=0.06332297213907254, w1=-0.04278810924466334\n",
      "Gradient Descent(21/49): loss=0.4182758890752872, w0=0.06554436809672058, w1=-0.044421337034180636\n",
      "Gradient Descent(22/49): loss=0.41627057058900885, w0=0.06770804357938576, w1=-0.046024584915012046\n",
      "Gradient Descent(23/49): loss=0.4143681419133492, w0=0.0698155721499729, w1=-0.0475985809443553\n",
      "Gradient Descent(24/49): loss=0.4125627936281442, w0=0.07186848286525153, w1=-0.04914403163265227\n",
      "Gradient Descent(25/49): loss=0.41084907179131863, w0=0.07386826158929284, w1=-0.05066162267956529\n",
      "Gradient Descent(26/49): loss=0.4092218544722424, w0=0.07581635226613687, w1=-0.05215201968227289\n",
      "Gradient Descent(27/49): loss=0.40767632994348074, w0=0.077714158153031, w1=-0.053615868817190555\n",
      "Gradient Descent(28/49): loss=0.4062079764069461, w0=0.07956304301553342, w1=-0.055053797496176324\n",
      "Gradient Descent(29/49): loss=0.4048125431401374, w0=0.08136433228573056, w1=-0.05646641499823729\n",
      "Gradient Descent(30/49): loss=0.4034860329570444, w0=0.08311931418477368, w1=-0.05785431307771093\n",
      "Gradient Descent(31/49): loss=0.4022246858864871, w0=0.08482924081089835, w1=-0.05921806654985514\n",
      "Gradient Descent(32/49): loss=0.40102496397817927, w0=0.08649532919404987, w1=-0.06055823385474221\n",
      "Gradient Descent(33/49): loss=0.3998835371537398, w0=0.08811876231819907, w1=-0.06187535760031518\n",
      "Gradient Descent(34/49): loss=0.398797270026238, w0=0.0897006901123954, w1=-0.06316996508542953\n",
      "Gradient Descent(35/49): loss=0.39776320961773404, w0=0.09124223041156841, w1=-0.06444256880366962\n",
      "Gradient Descent(36/49): loss=0.39677857390966415, w0=0.0927444698880536, w1=-0.06569366692869644\n",
      "Gradient Descent(37/49): loss=0.3958407411658986, w0=0.09420846495478552, w1=-0.06692374378185245\n",
      "Gradient Descent(38/49): loss=0.3949472399728688, w0=0.09563524264106867, w1=-0.06813327028271969\n",
      "Gradient Descent(39/49): loss=0.39409573994538216, w0=0.09702580144180549, w1=-0.06932270438329835\n",
      "Gradient Descent(40/49): loss=0.3932840430506198, w0=0.09838111214103112, w1=-0.07049249148644618\n",
      "Gradient Descent(41/49): loss=0.39251007550639366, w0=0.09970211861057535, w1=-0.07164306484919265\n",
      "Gradient Descent(42/49): loss=0.39177188021303294, w0=0.10098973858464468, w1=-0.07277484597151693\n",
      "Gradient Descent(43/49): loss=0.39106760968131166, w0=0.10224486441109046, w1=-0.07388824497115445\n",
      "Gradient Descent(44/49): loss=0.3903955194216293, w0=0.10346836378010323, w1=-0.07498366094497425\n",
      "Gradient Descent(45/49): loss=0.3897539617622371, w0=0.10466108043104831, w1=-0.07606148231744674\n",
      "Gradient Descent(46/49): loss=0.38914138006669224, w0=0.10582383483813404, w1=-0.07712208717670091\n",
      "Gradient Descent(47/49): loss=0.3885563033229129, w0=0.10695742487558034, w1=-0.07816584359864939\n",
      "Gradient Descent(48/49): loss=0.38799734107824196, w0=0.1080626264629334, w1=-0.07919310995964052\n",
      "Gradient Descent(49/49): loss=0.38746317869679586, w0=0.10914019419115042, w1=-0.08020423523807813\n"
     ]
    }
   ],
   "source": [
    "from stochastic_gradient_descent import *\n",
    "from gradient_descent import *\n",
    "from costs import *\n",
    "# weights_clean, t_loss_clean = least_squares(y_train_clean, tX_train_clean)\n",
    "# weights, t_loss = least_squares(y_train, tX_train)\n",
    "initial_w = np.zeros(tX_train_clean.shape[1])\n",
    "max_iters = 50\n",
    "gamma = 0.01\n",
    "batch_size=10\n",
    "losses, weights = gradient_descent(y_train_clean, tX_train_clean, initial_w, max_iters, gamma)\n",
    "weight_clean = weights[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-15T15:17:37.462896Z",
     "start_time": "2020-10-15T15:17:37.425556Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean training loss : 0.38695257291710555\n",
      "Clean validation loss : 0.38841011798491126\n"
     ]
    }
   ],
   "source": [
    "# print(\"Training loss : {}\".format(compute_loss(y_train, tX_train, weights)))\n",
    "# print(\"Validation loss : {}\".format(compute_loss(y_validation, tX_validation, weights)))\n",
    "print(\"Clean training loss : {}\".format(compute_loss(y_train_clean, tX_train_clean, weight_clean)))\n",
    "print(\"Clean validation loss : {}\".format(compute_loss(y_validation_clean, tX_validation_clean, weight_clean)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-15T14:44:35.025670Z",
     "start_time": "2020-10-15T14:44:27.779Z"
    }
   },
   "outputs": [],
   "source": [
    "_, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-15T14:44:35.029642Z",
     "start_time": "2020-10-15T14:44:27.956Z"
    }
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = DATA_FOLDER + 'submission.csv' \n",
    "y_pred = predict_labels(weights, tX_test)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
